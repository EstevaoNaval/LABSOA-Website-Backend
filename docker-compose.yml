version: "3"
services:
  # Serviço do Django (web)
  django-api:
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "1G"
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    volumes:
      - .:/app
      - ./data:/app/data
      - ./django-api-logs:/app/logs
      - media:/app/media
    ports:
      - "8000:8000"
    env_file:
      - .env
    depends_on:
      - labsoadb
      - rabbitmq
      - memcached

  django_tasks_worker:
    build:
      context: . # Usar o Dockerfile do pdf2chemicals
      dockerfile: Dockerfile
    restart: unless-stopped
    command: >
      celery -A labsoa_website_backend worker --queues=django_tasks --prefetch-multiplier=1 --concurrency=1 --loglevel=INFO
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: "4G"
    volumes:
      - .:/app # Montar o código do Django e o app pdf_processor como volume
      - ./data:/app/data
      - media:/app/media
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
    depends_on:
      - rabbitmq
    logging:
      driver: "json-file" # Default logging driver
      options:
        max-size: "10m" # Rotate logs after they reach 10 MB
        max-file: "3" # Keep a maximum of 3 log files

  # Serviço Celery Worker para PDF (com acesso ao Django e ao pdf_processor)
  pdf2chemicals_tasks_celery_worker:
    build:
      context: . # Usar o Dockerfile do pdf2chemicals
      dockerfile: Dockerfile
    restart: unless-stopped
    command: >
      celery -A labsoa_website_backend worker --queues=pdf2chemicals_tasks --prefetch-multiplier=1 --autoscale=3,1 --max-tasks-per-child=1 --loglevel=INFO
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: "4G"
    volumes:
      - .:/app # Montar o código do Django e o app pdf_processor como volume
      - ./data:/app/data
      - media:/app/media
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
    depends_on:
      - rabbitmq
    logging:
      driver: "json-file" # Default logging driver
      options:
        max-size: "10m" # Rotate logs after they reach 10 MB
        max-file: "3" # Keep a maximum of 3 log files

  labsoadb:
    build:
      context: ./labsoadb
      dockerfile: Dockerfile
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "2G"
    environment:
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_DB: ${DATABASE_NAME}
    ports:
      - "5432:5432"
    restart: unless-stopped

  redis:
    image: redis:7.2.4
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "2G"
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    restart: unless-stopped

  # Serviço RabbitMQ (broker de mensagens)
  rabbitmq:
    image: rabbitmq:4-management
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "1G"
    environment:
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: "-rabbit consumer_timeout 31622400000"
    ports:
      - "5672:5672" # Porta padrão do RabbitMQ
      - "15672:15672" # Porta para a interface de administração do RabbitMQ
    restart: unless-stopped

  clam_container_01:
    container_name: clam_container_01
    image: clamav/clamav:1.0.7
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "3G"
    ports:
      - "3310:3310"
      - "7357:7357"
    volumes:
      - clamav-data:/var/lib/clamav
      - clamav-logs:/var/log/clamav
    restart: unless-stopped

volumes:
  redis-data:
  media:
  clamav-data:
  clamav-logs:
  django-api-logs:
